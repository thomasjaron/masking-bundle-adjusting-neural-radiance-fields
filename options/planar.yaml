# default

group: 0_test                                               # name of experiment group
name: debug                                                 # name of experiment run
model:                                                      # type of model (must be specified from command line)
yaml:                                                       # config file (must be specified from command line)
seed: 0                                                     # seed number (for both numpy and pytorch)
gpu: 0                                                      # GPU index number
cpu: false                                                  # run only on CPU (not supported now)
load:                                                       # load checkpoint from filename

arch:                                                       # architectural options
    layers: [null,256,256,256,256,3]                        # hidden layers for MLP
    skip: []                                                # skip connections
    posenc:                                                 # positional encoding
        L_2D: 8                                             # number of bases (3D point)

barf_c2f:                                                   # coarse-to-fine scheduling on positional encoding

H: 360
W: 480
patch_H: 180
patch_W: 240

dataset: only_occlusions                                             # directory containing images
use_masks: True                                             # whether or not to utilize masks in loss calculation
use_edges: True                                             # whether to use sobel filter to align edges
alpha_initial: 1.0                                         # configuring alpha weight, loss = rbg_weight * rgb_loss + alpha * edge_loss
alpha_final: 0.9                                           # rgb_weight + alpha = 1                                      
use_cropped_images: True                                    # whether to use scaled down inputs for testing purposes or not

data:                                                       # data options
    root:                                                   # root path to dataset
    dataset:                                                # dataset name
    num_workers: 8                                          # number of parallel workers for data loading
    preload: false                                          # preload the entire dataset into the memory
    augment: {}                                             # data augmentation (training only)
        # rotate:                                           # random rotation
        # brightness: # 0.2                                 # random brightness jitter
        # contrast: # 0.2                                   # random contrast jitter
        # saturation: # 0.2                                 # random saturation jitter
        # hue: # 0.1                                        # random hue jitter
        # hflip: # True                                     # random horizontal flip
    center_crop:                                            # center crop the image by ratio
    val_on_test: false                                      # validate on test set during training
    train_sub:                                              # consider a subset of N training samples
    val_sub:                                                # consider a subset of N validation samples

warp:                                                       # image warping options
    type: homography                                        # type of warp function
    dof: 8                                                  # degrees of freedom of the warp function
    noise_h: 0.1                                            # scale of pre-generated warp perturbation (homography)
    noise_t: 0.2                                            # scale of pre-generated warp perturbation (translation)
    fix_first: false                                         # fix the first patch for uniqueness of solution


loss_weight:                                                # loss weights (in log scale)
    render: 0                                               # RGB rendering loss

optim:                                                      # optimization options
    lr: 1.e-3                                               # learning rate (main)
    lr_warp: 1.e-3                                          # learning rate of warp parameters
    lr_end:                                                 # terminal learning rate (only used with sched.type=ExponentialLR)
    algo: Adam                                              # optimizer (see PyTorch doc)
    sched: {}                                               # learning rate scheduling options
        # type: StepLR                                      # scheduler (see PyTorch doc)
        # steps:                                            # decay every N epochs
        # gamma: 0.1                                        # decay rate (can be empty if lr_end were specified)

batch_size: 5                                              # batch size (set to number of patches to consider)
max_iter: 3000                                             # train to maximum number of iterations

max_epoch: 1000                                             # train to maximum number of epochs
resume: false                                               # resume training (true for latest checkpoint, or number for specific epoch number)

output_root: output                                         # root path for output files (checkpoints and results)
tb:                                                         # TensorBoard options
    # num_images: [4,8]                                       # number of (tiled) images to visualize in TensorBoard
visdom:                                                     # Visdom options

freq:                                                       # periodic actions during training
    scalar: 20                                              # log losses and scalar states (every N iterations)
    vis: 100                                                # visualize results (every N iterations)
    val: 20                                                 # validate on val set (every N epochs)
    ckpt: 50                                                # save checkpoint (every N epochs)


################## Mask Generation
use_implicit_mask: True
N_vocab: 1500